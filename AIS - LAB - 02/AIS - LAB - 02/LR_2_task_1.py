try:
    import numpy as np
    import pandas as pd
    from sklearn import preprocessing
    from sklearn.svm import LinearSVC
    from sklearn.multiclass import OneVsOneClassifier
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
    import re
    import warnings
except ImportError as e:
    print(f"–ü–æ–º–∏–ª–∫–∞: –ù–µ –≤–¥–∞–ª–æ—Å—è —ñ–º–ø–æ—Ä—Ç—É–≤–∞—Ç–∏ –Ω–µ–æ–±—Ö—ñ–¥–Ω—ñ –±—ñ–±–ª—ñ–æ—Ç–µ–∫–∏: {e}")
    print("–ë—É–¥—å –ª–∞—Å–∫–∞, –≤—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å —ó—Ö –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é: pip install numpy pandas scikit-learn")
    exit(1)

warnings.filterwarnings('ignore')

COLUMNS = [
    'age', 'workclass', 'fnlwgt', 'education', 'education-num',
    'marital-status', 'occupation', 'relationship', 'race', 'sex',
    'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'
]
INPUT_FILE = 'income_data.txt'


def clean_data(data):
    """
    –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–∏—Ö: –≤–∏–¥–∞–ª–µ–Ω–Ω—è –∑–∞–π–≤–∏—Ö –ø—Ä–æ–±—ñ–ª—ñ–≤, –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—è —É –Ω–∏–∂–Ω—ñ–π —Ä–µ–≥—ñ—Å—Ç—Ä, 
    –≤–∏–¥–∞–ª–µ–Ω–Ω—è —Ä—è–¥–∫—ñ–≤ –∑ '?' (–≤—ñ–¥—Å—É—Ç–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è).
    """
    # –ó–∞–º—ñ–Ω–∞ '?' –Ω–∞ NaN —ñ –≤–∏–¥–∞–ª–µ–Ω–Ω—è —Ä—è–¥–∫—ñ–≤ –∑ NaN
    data = data.replace(r'^\s*\?+\s*$', np.nan, regex=True).dropna()

    for col in data.select_dtypes(include=['object']).columns:
        data[col] = data[col].astype(str).str.strip().str.lower()
        data[col] = data[col].apply(lambda x: re.sub(r'[^a-z0-9<=->]', '', x))

    return data


def encode_categorical_data(data):
    """–ö–æ–¥—É–≤–∞–Ω–Ω—è –∫–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω–∏—Ö –∑–º—ñ–Ω–Ω–∏—Ö –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é LabelEncoder"""
    label_encoders = {}
    
    data_encoded = data.copy()

    for column in data.columns:
        if data[column].dtype == 'object':
            le = preprocessing.LabelEncoder()
            data_encoded[column] = le.fit_transform(data_encoded[column])
            label_encoders[column] = le
    
    for col in data_encoded.columns:
        if data_encoded[col].dtype != 'object':
            data_encoded[col] = data_encoded[col].astype(int)

    return data_encoded, label_encoders


def evaluate_model(classifier, X_test, y_test):
    """
    –ü—Ä–æ–≥–Ω–æ–∑ —Ç–∞ –æ—Ü—ñ–Ω–∫–∞ —è–∫–æ—Å—Ç—ñ –º–æ–¥–µ–ª—ñ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ñ–π –≤–∏–±—ñ—Ä—Ü—ñ.
    """
    y_pred = classifier.predict(X_test)
    
    # –û–±—á–∏—Å–ª–µ–Ω–Ω—è –º–µ—Ç—Ä–∏–∫
    accuracy = accuracy_score(y_test, y_pred) * 100
    precision = precision_score(y_test, y_pred, average='weighted') * 100
    recall = recall_score(y_test, y_pred, average='weighted') * 100
    f1 = f1_score(y_test, y_pred, average='weighted') * 100

    print("\n" + "=" * 48)
    print("üîπ –û—Ü—ñ–Ω–∫–∞ –Ø–∫–æ—Å—Ç—ñ –ú–æ–¥–µ–ª—ñ –Ω–∞ –¢–µ—Å—Ç–æ–≤—ñ–π –í–∏–±—ñ—Ä—Ü—ñ üîπ")
    print(f"–ê–∫—É—Ä–∞—Ç–Ω—ñ—Å—Ç—å (Accuracy): {accuracy:.2f}%")
    print(f"–¢–æ—á–Ω—ñ—Å—Ç—å (Precision): {precision:.2f}%")
    print(f"–ü–æ–≤–Ω–æ—Ç–∞ (Recall): {recall:.2f}%")
    print(f"F1-–º—ñ—Ä–∞ (F1 Score): {f1:.2f}")
    print("=" * 48)

    return {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1}


def prepare_input_data(input_data, label_encoders):
    """–ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Ö—ñ–¥–Ω–∏—Ö –¥–∞–Ω–∏—Ö –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è"""

    input_df = pd.DataFrame([input_data], columns=COLUMNS[:-1])
    
    input_data_encoded = []
    
    for col in COLUMNS[:-1]:
        item = str(input_df[col].iloc[0]).strip().lower()
        item = re.sub(r'[^a-z0-9<=->]', '', item)
        
        try:
            if col in label_encoders:
                # –ö–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω–∞ –æ–∑–Ω–∞–∫–∞
                encoded_val = label_encoders[col].transform([item])[0]
            else:
                # –ß–∏—Å–ª–æ–≤–∞ –æ–∑–Ω–∞–∫–∞
                encoded_val = int(item)
            input_data_encoded.append(encoded_val)
        except ValueError as e:
            print(f"–ü–æ–º–∏–ª–∫–∞ –∫–æ–¥—É–≤–∞–Ω–Ω—è: –ó–Ω–∞—á–µ–Ω–Ω—è '{item}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –¥–ª—è –æ–∑–Ω–∞–∫–∏ '{col}'.")
            return None
    
    return pd.DataFrame([input_data_encoded], columns=COLUMNS[:-1])


def predict_income(classifier, label_encoders, input_data):
    """–ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –¥–æ—Ö–æ–¥—É –¥–ª—è –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö"""

    X_input = prepare_input_data(input_data, label_encoders)
    if X_input is None:
        return None

    # –ü—Ä–æ–≥–Ω–æ–∑
    prediction = classifier.predict(X_input)

    # –î–µ–∫–æ–¥—É–≤–∞–Ω–Ω—è —Ä–µ–∑
    predicted_income = label_encoders['income'].inverse_transform(prediction)[0]
    
    return predicted_income


def main():
    """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –ø—Ä–æ–≥—Ä–∞–º–∏"""
    try:
        # 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –ø–æ–ø–µ—Ä–µ–¥–Ω—è –æ–±—Ä–æ–±–∫–∞ –¥–∞–Ω–∏—Ö
        data = pd.read_csv(
            INPUT_FILE, 
            header=None, 
            names=COLUMNS, 
            sep=r'\s*,\s*', 
            engine='python', 
            na_values=['?']
        )
        
        data = clean_data(data)
        
        # 2. –ö–æ–¥—É–≤–∞–Ω–Ω—è –∫–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω–∏—Ö –æ–∑–Ω–∞–∫
        data_encoded, label_encoders = encode_categorical_data(data)

        # 3. –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ –æ–∑–Ω–∞–∫–∏ —Ç–∞ —Ü—ñ–ª—å–æ–≤—É –∑–º—ñ–Ω–Ω—É
        X = data_encoded.drop('income', axis=1)
        y = data_encoded['income']

        # 4. –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ –Ω–∞–≤—á–∞–ª—å–Ω—É —Ç–∞ —Ç–µ—Å—Ç–æ–≤—É –≤–∏–±—ñ—Ä–∫–∏
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=5
        )

        # 5. –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–∞ –Ω–∞–≤—á–∞–Ω–Ω—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä–∞
        classifier = OneVsOneClassifier(LinearSVC(random_state=0, dual="auto", max_iter=10000))
        print("–ü–æ—á–∏–Ω–∞—î—Ç—å—Å—è –Ω–∞–≤—á–∞–Ω–Ω—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ç–æ—Ä–∞...")
        classifier.fit(X_train, y_train)
        print("–ù–∞–≤—á–∞–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")

        # 6. –û—Ü—ñ–Ω–∫–∞ –º–æ–¥–µ–ª—ñ
        metrics = evaluate_model(classifier, X_test, y_test)
        
        # –ö—Ä–æ—Å-–≤–∞–ª—ñ–¥–∞—Ü—ñ—è
        f1_cv_scores = cross_val_score(classifier, X, y, scoring='f1_weighted', cv=3)
        print(f"F1 score (Cross-Validation, cv=3): {f1_cv_scores.mean() * 100:.2f}%")
        print("\n" + "=" * 40)

        # 7. –ü—Ä–æ–≥–Ω–æ–∑ –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ—ó —Ç–æ—á–∫–∏ –¥–∞–Ω–∏—Ö
        test_input_data = [
            '37', 'Private', '215646', 'HS-grad', '9', 'Never-married',
            'Handlers-cleaners', 'Not-in-family', 'White', 'Male',
            '0', '0', '40', 'United-States'
        ]
        
        print("\nüîπ –ü—Ä–æ–≥–Ω–æ–∑ –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ—ó —Ç–æ—á–∫–∏ –¥–∞–Ω–∏—Ö üîπ")
        print(f"–í—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ: {test_input_data}")
        
        predicted_income = predict_income(classifier, label_encoders, test_input_data)
        
        if predicted_income:
            print(f"–°–ø—Ä–æ–≥–Ω–æ–∑–æ–≤–∞–Ω–∏–π –∫–ª–∞—Å –¥–æ—Ö–æ–¥—É: {predicted_income.upper()}")
            print("=" * 40)

    except FileNotFoundError:
        print(f"–ü–æ–º–∏–ª–∫–∞: –§–∞–π–ª '{INPUT_FILE}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.")
    except Exception as e:
        print(f"–°—Ç–∞–ª–∞—Å—è –ø–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –≤–∏–∫–æ–Ω–∞–Ω–Ω—è: {e}")


if __name__ == "__main__":
    main()