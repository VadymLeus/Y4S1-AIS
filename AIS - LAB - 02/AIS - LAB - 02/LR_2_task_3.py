import numpy as np
import pandas as pd
from pandas.plotting import scatter_matrix
from matplotlib import pyplot as plt
import warnings

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC

warnings.filterwarnings('ignore')

RANDOM_STATE = 1
TEST_SIZE = 0.20
N_SPLITS = 10

def step_1_data_loading():
    iris_dataset = load_iris()

    print("="*60)
    print("–ö–†–û–ö 1. –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø –¢–ê –í–ò–í–ß–ï–ù–ù–Ø –î–ê–ù–ò–•")
    print("="*60)

    print("–ö–ª—é—á—ñ iris_dataset:", iris_dataset.keys())
    print("-" * 30)
    print("–ù–∞–∑–≤–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π:", iris_dataset['target_names'])
    print("–ù–∞–∑–≤–∞ –æ–∑–Ω–∞–∫:", iris_dataset['feature_names'])
    print("-" * 30)
    print("–§–æ—Ä–º–∞ –º–∞—Å–∏–≤—É data:", iris_dataset['data'].shape)
    print("–ü–µ—Ä—à—ñ 5 –ø—Ä–∏–∫–ª–∞–¥—ñ–≤:\n", iris_dataset['data'][:5])
    print("–í—ñ–¥–ø–æ–≤—ñ–¥—ñ:", iris_dataset['target'])
    print("-" * 30)

    url = "https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv"
    names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']
    dataset = pd.read_csv(url, names=names)

    print(f"–§–æ—Ä–º–∞ –¥–∞—Ç–∞—Å–µ—Ç—É: {dataset.shape}")
    print("\n–ü–µ—Ä—à—ñ 20 —Ä—è–¥–∫—ñ–≤:")
    print(dataset.head(20))
    print("\n–°—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω–µ –∑–≤–µ–¥–µ–Ω–Ω—è:")
    print(dataset.describe())
    print("\n–†–æ–∑–ø–æ–¥—ñ–ª –∑–∞ –∫–ª–∞—Å–∞–º–∏:")
    print(dataset.groupby('class').size())
    
    return dataset

def step_2_visualization(dataset):
    print("\n" + "="*60)
    print("–ö–†–û–ö 2. –í–Ü–ó–£–ê–õ–Ü–ó–ê–¶–Ü–Ø –î–ê–ù–ò–•")
    print("="*60)

    dataset.plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False)
    plt.suptitle('–î—ñ–∞–≥—Ä–∞–º–∞ —Ä–æ–∑–º–∞—Ö—É –∞—Ç—Ä–∏–±—É—Ç—ñ–≤')
    plt.show()

    dataset.hist()
    plt.suptitle('–ì—ñ—Å—Ç–æ–≥—Ä–∞–º–∞ —Ä–æ–∑–ø–æ–¥—ñ–ª—É –∞—Ç—Ä–∏–±—É—Ç—ñ–≤')
    plt.show()

    scatter_matrix(dataset, figsize=(12, 12))
    plt.suptitle('–ú–∞—Ç—Ä–∏—Ü—è –¥—ñ–∞–≥—Ä–∞–º —Ä–æ–∑—Å—ñ—é–≤–∞–Ω–Ω—è')
    plt.show()

def step_3_split_data(dataset):
    print("\n" + "="*60)
    print("–ö–†–û–ö 3. –°–¢–í–û–†–ï–ù–ù–Ø –ù–ê–í–ß–ê–õ–¨–ù–û–ì–û –¢–ê –¢–ï–°–¢–û–í–û–ì–û –ù–ê–ë–û–†–Ü–í")
    print("="*60)

    array = dataset.values
    X = array[:, 0:4].astype(float)
    y = array[:, 4]

    X_train, X_validation, Y_train, Y_validation = train_test_split(
        X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE
    )

    print(f"X_train.shape: {X_train.shape}")
    print(f"X_validation.shape: {X_validation.shape}")
    
    return X_train, X_validation, Y_train, Y_validation

def step_4_compare_models(X_train, Y_train):
    print("\n" + "="*60)
    print("–ö–†–û–ö 4. –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø –ú–û–î–ï–õ–ï–ô")
    print("="*60)

    models = [
        ('LR', LogisticRegression(solver='liblinear', multi_class='ovr', random_state=RANDOM_STATE)),
        ('LDA', LinearDiscriminantAnalysis()),
        ('KNN', KNeighborsClassifier()),
        ('CART', DecisionTreeClassifier(random_state=RANDOM_STATE)),
        ('NB', GaussianNB()),
        ('SVM', SVC(gamma='auto', random_state=RANDOM_STATE))
    ]

    results = []
    names = []
    print("–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ 10-–∫—Ä–∞—Ç–Ω–æ—ó –∫—Ä–æ—Å-–≤–∞–ª—ñ–¥–∞—Ü—ñ—ó (Accuracy):")

    for name, model in models:
        kfold = StratifiedKFold(n_splits=N_SPLITS, random_state=RANDOM_STATE, shuffle=True)
        cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')
        results.append(cv_results)
        names.append(name)
        print('%s: %.4f (%.4f)' % (name, cv_results.mean(), cv_results.std()))

    plt.boxplot(results, labels=names)
    plt.title('–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤ (Accuracy)')
    plt.show()
    
    best_name = names[np.argmax([r.mean() for r in results])]
    return best_name

def step_6_7_evaluate_best(X_train, X_validation, Y_train, Y_validation, best_model_name):
    print("\n" + "="*60)
    print(f"–ö–†–û–ö 6 & 7. –û–¶–Ü–ù–ö–ê –ú–û–î–ï–õ–Ü ({best_model_name})")
    print("="*60)
    
    if best_model_name == 'SVM':
        best_model = SVC(gamma='auto', random_state=RANDOM_STATE)
    elif best_model_name == 'LDA':
        best_model = LinearDiscriminantAnalysis()
    elif best_model_name == 'KNN':
        best_model = KNeighborsClassifier()
    else:
        best_model = SVC(gamma='auto', random_state=RANDOM_STATE)
        best_model_name = 'SVM'

    best_model.fit(X_train, Y_train)
    predictions = best_model.predict(X_validation)

    print(f"üîπ –û—Ü—ñ–Ω–∫–∞ {best_model_name} –Ω–∞ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ñ–π –≤–∏–±—ñ—Ä—Ü—ñ üîπ")
    print(f"–¢–æ—á–Ω—ñ—Å—Ç—å: {accuracy_score(Y_validation, predictions):.4f}")

    print("\n–ú–∞—Ç—Ä–∏—Ü—è –ø–æ–º–∏–ª–æ–∫:")
    print(confusion_matrix(Y_validation, predictions))

    print("\n–ó–≤—ñ—Ç –ø—Ä–æ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—é:")
    print(classification_report(Y_validation, predictions))
    
    return best_model

def step_8_predict_new(best_model):
    print("\n" + "="*60)
    print("–ö–†–û–ö 8. –ü–†–û–ì–ù–û–ó –î–õ–Ø –ù–û–í–ò–• –î–ê–ù–ò–•")
    print("="*60)

    X_new = np.array([[5.0, 2.9, 1.0, 0.2]])
    prediction = best_model.predict(X_new)
    predicted_label = prediction[0]

    print(f"–§–æ—Ä–º–∞ –º–∞—Å–∏–≤—É X_new: {X_new.shape}")
    print(f"–°–ø—Ä–æ–≥–Ω–æ–∑–æ–≤–∞–Ω–∞ –º—ñ—Ç–∫–∞: {predicted_label}")
    print("="*60)

if __name__ == "__main__":
    data_frame = step_1_data_loading()
    step_2_visualization(data_frame)
    X_train, X_validation, Y_train, Y_validation = step_3_split_data(data_frame)
    best_model_name = step_4_compare_models(X_train, Y_train)
    best_model = step_6_7_evaluate_best(X_train, X_validation, Y_train, Y_validation, best_model_name)
    step_8_predict_new(best_model)